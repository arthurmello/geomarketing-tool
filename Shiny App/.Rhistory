nablaV=(2/β)*(Xy-XX%*%L)-α*deriv(ω,'αL')
nablaV=nablaV-4*L./(τ^2+L.^2)
L=L+h*nablaV+sqrt(2*h)*rnorm(1,M)
H=H+h
lambda=lambda+h*L/T
}
return(lambda)
}
setwd('/Users/arthurmello/Library/Mobile Documents/com~apple~CloudDocs/Geral/Acadêmico/Mestrado/M2/M2.2/Big Data')
# Exercise 1 data
setwd('/Users/arthurmello/Library/Mobile Documents/com~apple~CloudDocs/Geral/Acadêmico/Mestrado/M2/M2.2/Big Data')
sick <- read.csv("First_dataset.csv", header = TRUE)
# STRUCTURE OF THE DATA
str(sick)
sick$Outcome <- as.factor(sick$Outcome)
# SUMMARY STATS TABLE
summary(sick)
data$Outcome <- as.factor(data$Outcome)
data$Outcome
setwd('/Users/arthurmello/Library/Mobile Documents/com~apple~CloudDocs/Geral/Acadêmico/Mestrado/M2/M2.2/Big Data')
data <- read.csv("First_dataset.csv", header = TRUE)
# STRUCTURE OF THE DATA
str(data)
data$Outcome <- as.factor(data$Outcome)
# SUMMARY STATS TABLE
summary(data)
data$Outcome <- as.factor(data$Outcome)
table(data$Outcome)
ggplot(data, aes(Outcome,fill = Outcome)) +
geom_bar() +
ggtitle("Distribution of Outcome variable")
library(ggplot2)
ggplot(data, aes(Outcome,fill = Outcome)) +
geom_bar() +
ggtitle("Distribution of Outcome variable")
par(mfrow = c(1,2))
i <- 2
for (i in 1:8){
hist(data[,i], breaks = "Sturges", main = paste("Histogram of ", colnames(data)[i]), xlab = colnames(data)[i])
plot(sort(data[,i]), pch = ".",
main = paste("Index plot of the sorted ",colnames(data)[i], " values", sep = ""),
ylab = colnames(data)[i])
}
data$Glucose[data$Glucose == 0] <- NA
data$BloodPressure[data$BloodPressure == 0] <- NA
data$SkinThickness[data$SkinThickness == 0] <- NA
data$Insulin[data$Insulin == 0] <- NA
data$BMI[data$BMI == 0] <- NA
gg_miss_var(data[, c(2:6)], show_pct = T)
library(ggthemes)
library(corrplot)
library(caret)
require(caret)
library(corrplot)
require(caret)
library(ggplot2)
library(reshape)
library(gridExtra)
library(ggthemes)
library(caret)
require(caret)
library(corrplot)
library(ggplot2)
library(reshape)
library(gridExtra)
library(ggthemes)
require(caret)
library(Hmisc)
library(DMwR)
install.packages('DMwR')
library(DMwR)
library(e1071)
library(verification)
install.packages('verification')
install.packages('verification')
library(verification)
library(randomForest)
library(dplyr)
library(tidyr)
gg_miss_var(data[, c(2:6)], show_pct = T)
library(naniar)
install.packages('naniar')
library(naniar)
gg_miss_var(data[, c(2:6)], show_pct = T)
for (i in 2:6){
cat_zero_or_not <- ifelse(is.na(data[,i]), "zero", "non-zero")
test <- chisq.test(cat_zero_or_not, data[, "Outcome"])
if (test$p.value >= 0.05){
print(paste("At 5%, we fail to reject the null hypothesis that there is no statistical correlation between the 0's and", colnames(data)[i], sep = ""))
}else{
print(paste("There is a statistical correlation between the 0's and ", colnames(data)[i], sep = ""))
}
}
data_input <- data
data_input[,-9] <- knninputation(data_input[,-9], k = 5)
data_input <- data
data_input[,-9] <- knnimputation(data_input[,-9], k = 5)
data_input[,-9] <- knnImputation(data_input[,-9], k = 5)
# Densities of explanatory variables
var.num <- data_input[,-9]
melt.num <- melt(var.num)
ggplot(data = melt.num, aes(x = value)) +
stat_density(fill="darkblue") +
facet_wrap(~variable, scales = "free")
# Boxplots of explanatory variables
b1 <- ggplot(data_input, aes(x = Outcome, y = Pregnancies,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b2 <- ggplot(data_input, aes(x = Outcome, y = Glucose,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b3 <- ggplot(data_input, aes(x = Outcome, y = BloodPressure,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b4 <- ggplot(data_input, aes(x = Outcome, y = SkinThickness,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b5 <- ggplot(data_input, aes(x = Outcome, y = Insulin,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b6 <- ggplot(data_input, aes(x = Outcome, y = BMI,fill = Outcome)) +
geom_boxplot(binwidth = 5) +
theme(legend.position = "bottom")
b7 <- ggplot(data_input, aes(x = Outcome, y = DiabetesPedigreeFunction,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
b8 <- ggplot(data_input, aes(x = Outcome, y = Age,fill = Outcome)) +
geom_boxplot() +
theme(legend.position = "bottom")
gridExtra::grid.arrange(b1, b2, b3, b4, b5, b6, b7, b8, ncol = 4)
within_var <- c()
set.seed(420)
for (i in 2:10){
res_km <- kmeans(scale(data_input[, -9]), i, nstart = 20)
within_var <- c(within_var, res_km$tot.withinss)
}
plot(within_var)
set.seed(420)
res_km_fin <- kmeans(scale(data_input[, -9]), 4, nstart = 20)
data$clust_input_km <- res_km_fin$cluster
data_cat <- data[, c(1,7:9)]
data$Outcome <- as.numeric(data$Outcome)-1
for (i in 2:6){
print(colnames(data)[i])
smb <- smbinning(data, y="Outcome", x=colnames(data)[i])
if (class(smb) != "character"){
data_cat[, colnames(data)[i]] <- cut(data[,i], unique(c(min(data[,i], na.rm = T), smb$cuts, max(data[,i], na.rm = T))), include.lowest = T, dig.lab = 4)
data_cat[, colnames(data)[i]] <- fct_explicit_na(data_cat[, colnames(data)[i]], na_level = "<NA>")
}
}
within_var <- c()
set.seed(420)
for (i in 2:10){
res_km <- kmeans(scale(data_input[, -9]), i, nstart = 20)
within_var <- c(within_var, res_km$tot.withinss)
}
plot(within_var)
set.seed(420)
res_km_fin <- kmeans(scale(data_input[, -9]), 4, nstart = 20)
data$clust_input_km <- res_km_fin$cluster
litmix(data_cat[, -4])
split <- splitmix(data_cat[, -4])
install.packages('PCAmixdata)
install.packages('PCAmixdata')
library(PCAmixdata)
split <- splitmix(data_cat[, -4])
X1 <- scale(split$X.quanti)
X2 <- split$X.quali
res <- PCAmix(X.quanti=X1, X.quali=X2, ndim=2, rename.level = T)
res_data_coords <- res$ind$coord
within_var <- c()
set.seed(123)
for (i in 2:10){
res_km <- kmeans(res_data_coords, i, nstart = 20)
within_var <- c(within_var, res_km$tot.withinss)
}
plot(within_var)
res_km_fin <- kmeans(res_data_coords, 4, nstart = 20)
data$clust_cat_km <- res_km_fin$cluster
tab <- aggregate(data$Outcome, by = list(data$clust_input_km), FUN = mean)
p1 <- ggplot(data=tab, aes(x=Group.1, y=x)) +
geom_bar(stat="identity", fill="steelblue")+
geom_text(aes(label=round(x,2)), vjust=1.6, color="white", size=3.5)+
xlab('KMeans clustering with inputed missing data') + ylab('% of Outcome = 1')+
theme_minimal()
p1
p1 <- ggplot(data=tab, aes(x=Group.1, y=x)) +
geom_bar(stat="identity", fill="light blue")+
geom_text(aes(label=round(x,2)), vjust=1.6, color="white", size=3.5)+
xlab('KMeans clustering with inputed missing data') + ylab('% of Outcome = 1')+
theme_minimal()
p1
set.seed(123)
train <- createDataPartition(data$Outcome, p = 0.7, list = FALSE)
require(caret)
library(caret)
install.packages('robustbase)
install.packages('robustbase')
library(robustbase)
install.packages('robustbase')
library(robustbase)
library(caret)
set.seed(123)
train <- createDataPartition(data$Outcome, p = 0.7, list = FALSE)
# data_input
train_input <- data_input[train, ]
test_input <- data_input[-train,]
# data_cat
train_cat <- data_cat[train, ]
test_cat <- data_cat[-train,]
glm_input <- glm(Outcome ~ . , data=train_input, family = binomial)
step_model_input <- step(glm_input)
step_model_input
summary(step_model_input)
library(e1071)
nbclassifier <- naiveBayes(Outcome ~ . , data=train_input)
summary(nbclassifier)
nbclassifier
svm_input <- svm(Outcome~., data = train_input,kernel = "radial", cost = 1, gamma = 0.1,probability = TRUE)
svm_input <- svm(Outcome~., data = train_input,kernel = "radial", cost = 0.7, gamma = 0.2,probability = TRUE)
nbclassifier_pred <- predict(nbclassifier, test_input)
table(test_input$Outcome, test_input)
test_input$Outcome
table(test_input$Outcome, nbclassifier_pred)
# Logistic Regression
pred_input_glm <- predict(glm_input_fin, newdata = test_input,type = "response")
pred_input_glm <- predict(glm_input, newdata = test_input,type = "response")
optCutOff <- optimalCutoff(test_input$Outcome, pred_input_glm)[1]
library(MKmisc)
install.packages('MKmisc')
library(MKmisc)
optCutOff <- optimalCutoff(test_input$Outcome, pred_input_glm)[1]
optmalCutoff(test_input$Outcome, pred_input_glm)[1]
optCutoff(test_input$Outcome, pred_input_glm)[1]
pred_input_glm <- predict(glm_input, newdata = test_input,type = "response")
pred_input_glm
predictions_input_glm <- ifelse(pred_input_glm < 0.5, 0, 1)
table(as.factor(test_input$Outcome), predictions_input_glm)
# Naive Bayes Classifier
nbclassifier_pred <- predict(nbclassifier, test_input)
table(test_input$Outcome, nbclassifier_pred)
# SVM
svm_input_pred <- predict(svm_input_fin, test_input)
svm_input_pred <- predict(svm_input_, test_input)
svm_input_pred <- predict(svm_input, test_input)
?predict
svm_input_pred <- predict(svm_input, test_input)
table(test_input$Outcome, svm_input_pred)
nbclassifier_pred
rocplot2 <- roc.plot(x = (test_input$Outcome == "1"),
pred = cbind(predictions_input_glm, nbclassifier_pred, attr(svm_input_pred, "probabilities")[,2]),
main = "ROC curve",
legend = T, leg.text = c("GLM","NB","SVM"))
predictions_input_glm
nbclassifier_pred
attr(svm_input_pred, "probabilities")[,2])
attr(svm_input_pred, "probabilities")[,2]
svm_input_pred
rocplot2 <- roc.plot(x = (test_input$Outcome == "1"),
pred = cbind(predictions_input_glm, nbclassifier_pred, svm_input_pred),
main = "ROC curve",
legend = T, leg.text = c("GLM","NB","SVM"))
predictions_input_glm
nbclassifier_pred
svm_input_pred
svm_input_pred[1]
class(svm_input_pred)
class(predictions_input_glm)
test_input$Outcome
AUC = auc(roc(as.factor(predictions_input_glm),y_test)) #Slight improvement from model1
library(pROC)
AUC = auc(roc(as.factor(predictions_input_glm),y_test))
y_test = test_input$Outcome
AUC = auc(roc(as.factor(predictions_input_glm),y_test))
y_test
as.factor(predictions_input_glm)
as.numeric(y_test)
y_test = as.numeric(test_input$Outcome)
AUC = auc(roc(predictions_input_glm,y_test))
AUC_nbc = auc(roc(nbclassifier_pred,y_test))
AUC_glm = auc(roc(predictions_input_glm,y_test))
AUC_svm = auc(roc(svm_input_pred,y_test))
AUC_svm
AUC_nbc
AUC_glm
mean(predictions_input_glm!=y_test)
predictions_input_glm
y_test
test_input$Outcome
as.numeric(test_input$Outcome)
y_test = as.numeric(as.character(test_input$Outcome))
y_test
AUC_glm = auc(roc(predictions_input_glm,y_test))
AUC_nbc = auc(roc(nbclassifier_pred,y_test))
AUC_svm = auc(roc(svm_input_pred,y_test))
AUC_glm
AUC_nbc
AUC_svm
mean(predictions_input_glm!=y_test)
misclassification_rate = mean(predictions_input_glm!=y_test)
misclassification_rate
summary(svm_input)
barplot(data$Outcome)
barplot(table(data$Outcome))
par(mfrow = c(1,1))
i <- 2
for (i in 1:8){
hist(data[,i], breaks = "Sturges", main = paste("Histogram of ", colnames(data)[i]), xlab = colnames(data)[i])
}
?hist
i <- 2
for (i in 1:8){
hist(data[,i], breaks = "Sturges", main = paste("Histogram of ", colnames(data)[i]), xlab = colnames(data)[i], col='light blue')
}
par(mfrow=c(2,4))
i <- 2
for (i in 1:8){
hist(data[,i], breaks = "Sturges", main = paste("Histogram of ", colnames(data)[i]), xlab = colnames(data)[i], col='light blue')
}
data$Outcome
tab <- aggregate(data$Outcome, by = list(data$clust_input_km), FUN = mean)
p <- ggplot(data=tab, aes(x=Group.1, y=x)) +
geom_bar(stat="identity", fill="light blue")+
geom_text(aes(label=round(x,2)), vjust=1.6, color="white", size=3.5)+
xlab('KMeans clustering with inputed missing data') + ylab('% of Outcome = 1')+
theme_minimal()
p
as.numeric(data$Outcome)
as.numeric(data$Outcome)
as.numeric(data$Outcome)-1
print('AUC GLM:',AUC_glm)
print('AUC Naive Bayes Classifier:',AUC_nbc)
print('AUC SVM:',AUC_svm)
print(paste('AUC GLM:',AUC_glm))
print(paste('AUC Naive Bayes Classifier:',AUC_nbc))
print(paste('AUC SVM:',AUC_svm))
library(ppls)
library(xgboost)
library(JOUSBoost)
# Exercise 1 data
setwd('/Users/arthurmello/Library/Mobile Documents/com~apple~CloudDocs/Geral/Acadêmico/Mestrado/M2/M2.2/Big Data')
data <- read.csv("First_dataset.csv", header = TRUE)
# Exercise 2 data
data(cookie)
# Extraction of the sugar rate and spectrum
cook = data.frame(cookie[,702],cookie[,1:700])
names(cook)= c("sucre",paste("X",1:700,sep=""))
?hist
var <- c()
set.seed(123)
for (i in 2:10){
res_km <- kmeans(scale(data_input[, -9]), i, nstart = 10)
var <- c(var, res_km$tot.withinss)
}
library(ppls)
library(xgboost)
library(JOUSBoost)
# Exercise 1 data
setwd('/Users/arthurmello/Library/Mobile Documents/com~apple~CloudDocs/Geral/Acadêmico/Mestrado/M2/M2.2/Big Data')
data <- read.csv("First_dataset.csv", header = TRUE)
# Exercise 2 data
data(cookie)
# Extraction of the sugar rate and spectrum
cook = data.frame(cookie[,702],cookie[,1:700])
names(cook)= c("sucre",paste("X",1:700,sep=""))
library(corrplot)
library(ggplot2)
library(reshape)
library(gridExtra)
library(ggthemes)
library(robustbase)
library(caret)
library(Hmisc)
library(DMwR)
library(e1071)
library(verification)
library(randomForest)
library(dplyr)
library(tidyr)
library(naniar)
library(PCAmixdata)
library(e1071)
library(MKmisc)
library(pROC)
data$Outcome <- as.factor(data$Outcome)
?hist
par(mfrow=c(2,4))
i <- 2
for (i in 1:8){
hist(data[,i], main = colnames(data)[i], xlab = colnames(data)[i], col='light blue')
}
data$Glucose[data$Glucose == 0] <- NA
data$BloodPressure[data$BloodPressure == 0] <- NA
data$SkinThickness[data$SkinThickness == 0] <- NA
data$Insulin[data$Insulin == 0] <- NA
data$BMI[data$BMI == 0] <- NA
data_input <- data
data_input[,-9] <- knnImputation(data_input[,-9], k = 3)
var <- c()
set.seed(123)
for (i in 2:10){
res_km <- kmeans(scale(data_input[, -9]), i, nstart = 10)
var <- c(var, res_km$tot.withinss)
}
var
shiny::runApp('Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
sum(INSEE@data[,'P14_POP_IMM'])
# Loading libraries and Token_map_box
library('tidyverse')
library('leaflet')
library('shiny')
Token_map_box = 'https://api.mapbox.com/styles/v1/arthurmello/cjrrhiraq019v2sl8kz15p59p/tiles/256/{z}/{x}/{y}@2x?access_token=pk.eyJ1IjoiYXJ0aHVybWVsbG8iLCJhIjoiY2pycmhkcXRxMXphajQzbXRoZ2dqMTFsdiJ9.SGlFjvQl9cNE4cM5k5EnaQ'
# Getting current file location
getCurrentFileLocation <-  function()
{
this_file <- commandArgs() %>%
tibble::enframe(name = NULL) %>%
tidyr::separate(col=value, into=c("key", "value"), sep="=", fill='right') %>%
dplyr::filter(key == "--file") %>%
dplyr::pull(value)
if (length(this_file)==0)
{
this_file <- rstudioapi::getSourceEditorContext()$path
}
return(dirname(this_file))
}
setwd(getCurrentFileLocation())
path = dirname(getCurrentFileLocation())
# Loading data
load(paste(path,"/data/INSEE.RData",sep = ""))
INSEE@data[,'P14_POP_IMM'
INSEE@data[,'P14_POP_IMM']
final_score = reactive({INSEE@data[,'P14_POP_IMM']})
final_score
pal <- reactive({
colorQuantile("RdYlGn", INSEE@data[,final_score()], n = 5)
})
pal
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
data.frame(c('a','b','c'),c(1,2,3))
data.frame(c('a',1,2),c('b',2,3))
colSums(data.frame(c('a',1,2),c('b',2,3)))
colSums(data.frame(c(1,2),c(2,3)))
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE
})
for (i in c('0014','1529','3044','4559','6074','75P')){
INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE
}
for (i in c('0014','1529','3044','4559','6074','75P')){
print(INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE)
}
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
print(INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE)
})
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE
})
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE
}, na.rm = TRUE)
})
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE
}, na.rm = TRUE)
length(INSEE@data)
c(rep(0,length(INSEE@data)))
x = c(rep(0,length(INSEE@data)))
sum(for (i in c('0014','1529','3044','4559','6074','75P')){
x = colSums(x, INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE)
})
x
x = c(rep(0,length(INSEE@data)))
for (i in c('0014','1529','3044','4559','6074','75P')){
x = colSums(cbind(x, (INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE)))
}
x
x = c(rep(0,length(INSEE@data)))
paste('P14_', 'POP', '75P', sep = "")
INSEE@data[,paste('P14_', 'POP', '75P', sep = "")]
(INSEE@data[,paste('P14_', 'POP', '75P', sep = "")] * TRUE)
cbind(x, (INSEE@data[,paste('P14_', 'POP', '75P', sep = "")] * TRUE))
colSums(cbind(x, (INSEE@data[,paste('P14_', 'POP', '75P', sep = "")] * TRUE)))
rowSums(cbind(x, (INSEE@data[,paste('P14_', 'POP', '75P', sep = "")] * TRUE)))
x = c(rep(0,nrow(INSEE@data)))
x = rowSums(cbind(x, (INSEE@data[,paste('P14_', 'POP', '75P', sep = "")] * TRUE)))
x
x = c(rep(0,nrow(INSEE@data)))
for (i in c('0014','1529','3044','4559','6074','75P')){
x = rowSums(cbind(x, (INSEE@data[,paste('P14_', 'POP', i, sep = "")] * TRUE)))
}
x
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
x = c(rep(0,nrow(INSEE@data)))
final_score = reactive({
for (i in c('0014','1529','3044','4559','6074','75P')){
x = rowSums(cbind(x, (INSEE@data[,paste('P14_', sex(), i, sep = "")] * input$i)))
}
x
})
pal <- reactive({
colorQuantile("RdYlGn", final_score(), n = 5)
})
pal
x
runApp('~/Library/Mobile Documents/com~apple~CloudDocs/Geral/Outros/Portfólio/Geomarketing tool/Shiny App')
